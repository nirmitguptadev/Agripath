import os
import json
import re # <-- ADD THIS IMPORT for the post-processing step
import requests
import google.generativeai as genai
from django.conf import settings
from django.http import JsonResponse
from django.shortcuts import render
from django.views.decorators.csrf import csrf_exempt
from django.contrib.auth.decorators import login_required

# --- API Configuration (no changes) ---
MODEL = None
try:
    GEMINI_API_KEY = settings.GEMINI_API_KEY
    OPENWEATHER_API_KEY = settings.OPENWEATHER_API_KEY
    genai.configure(api_key=GEMINI_API_KEY)
    MODEL = genai.GenerativeModel('gemini-2.5-flash-lite')
    print("‚úÖ Successfully configured Gemini and Weather APIs.")
except (AttributeError, Exception) as e:
    print(f"üî¥ FATAL ERROR: Could not configure API keys. Error: {e}")
    GEMINI_API_KEY = None
    OPENWEATHER_API_KEY = None

# --- [MODIFIED] Centralized Gemini Response Function with Post-Processing ---
def generate_gemini_response(prompt_content):
    if not MODEL:
        print("üî¥ Attempted to call Gemini, but the model is not configured.")
        return "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•á‡§∞‡§æ AI ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§†‡•Ä‡§ï ‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§"
    try:
        response = MODEL.generate_content(prompt_content)
        
        # [NEW] Post-processing step to guarantee no special characters
        # This will remove common markdown characters like *, #, -, etc.
        raw_text = response.text
        cleaned_text = re.sub(r'[!@#$*_-]', '', raw_text)
        
        return cleaned_text.strip() # Return the cleaned text
        
    except Exception as e:
        print(f"üî¥üî¥üî¥ GEMINI API ERROR üî¥üî¥üî¥: {e}")
        return "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, AI ‡§∏‡•á ‡§ï‡§®‡•á‡§ï‡•ç‡§ü ‡§ï‡§∞‡§§‡•á ‡§∏‡§Æ‡§Ø ‡§è‡§ï ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§π‡•Å‡§à‡•§"

# --- Weather Helper Function (no changes) ---
def get_weather_data(city_name):
    # ... (no changes in this function)
    if not OPENWEATHER_API_KEY: return None, "Weather API key not configured."
    base_url = "http://api.openweathermap.org/data/2.5/weather"
    params = {'q': city_name, 'appid': OPENWEATHER_API_KEY, 'units': 'metric', 'lang': 'hi'}
    try:
        response = requests.get(base_url, params=params)
        if response.status_code == 404: return None, f"City '{city_name}' not found."
        response.raise_for_status()
        data = response.json()
        return { "city": data.get("name"), "temperature": data["main"]["temp"], "description": data["weather"][0]["description"], "humidity": data["main"]["humidity"], "wind_speed": data["wind"]["speed"], }, None
    except requests.exceptions.RequestException as e:
        print(f"üî¥ Weather API request error: {e}")
        return None, "Could not connect to the weather service."

# ==============================================================================
#  [MODIFIED] HANDLER FUNCTIONS - With more natural persona and instructions
# ==============================================================================

# This is our new, more natural persona prompt
PERSONA_PROMPT = {
    'role': 'user', 
    'parts': [
        "‡§Ü‡§™ 'AgriPath' ‡§®‡§æ‡§Æ ‡§ï‡•á ‡§è‡§ï ‡§Æ‡§ø‡§§‡•ç‡§∞‡§µ‡§§ ‡§î‡§∞ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞ AI ‡§ï‡•É‡§∑‡§ø ‡§Æ‡§ø‡§§‡•ç‡§∞ ‡§π‡•à‡§Ç‡•§ ‡§Ü‡§™‡§ï‡•Ä ‡§¨‡•ã‡§≤‡•Ä ‡§∏‡§∞‡§≤ ‡§î‡§∞ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§π‡•à, ‡§ú‡•à‡§∏‡•á ‡§Ü‡§™ ‡§ó‡§æ‡§Å‡§µ ‡§ï‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡§ø‡§∏‡§æ‡§® ‡§Æ‡§ø‡§§‡•ç‡§∞ ‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•ã‡§Ç‡•§ ‡§Ö‡§™‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•ç‡§µ‡§æ‡§≠‡§æ‡§µ‡§ø‡§ï, ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§î‡§∞ ‡§∏‡§Ç‡§µ‡§æ‡§¶‡•Ä ‡§∞‡§ñ‡•á‡§Ç‡•§"
    ]
}
PERSONA_ACK = {'role': 'model', 'parts': ['‡§ú‡•Ä, ‡§Æ‡•à‡§Ç ‡§∏‡§Æ‡§ù ‡§ó‡§Ø‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§ï‡§ø‡§∏‡§æ‡§® ‡§Æ‡§ø‡§§‡•ç‡§∞ ‡§ï‡•Ä ‡§§‡§∞‡§π ‡§∏‡§∞‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ‡•§']}


def handle_weather_query(user_prompt, history):
    city_extraction_prompt = f"‡§á‡§∏ ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡•á ‡§ï‡•á‡§µ‡§≤ ‡§∂‡§π‡§∞ ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§®‡§ø‡§ï‡§æ‡§≤‡•á‡§Ç: '{user_prompt}'. ‡§ï‡•á‡§µ‡§≤ ‡§è‡§ï ‡§∂‡§¨‡•ç‡§¶ ‡§Æ‡•á‡§Ç ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç‡•§"
    city_name = generate_gemini_response(city_extraction_prompt).strip()

    if not city_name or "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç" in city_name or len(city_name.split()) > 3:
        return "‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∂‡§π‡§∞ ‡§∏‡§Æ‡§ù ‡§®‡§π‡•Ä‡§Ç ‡§™‡§æ‡§Ø‡§æ‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§¨‡§§‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§"

    weather_data, error = get_weather_data(city_name)
    if error:
        return f"‡§Æ‡•Å‡§ù‡•á '{city_name}' ‡§®‡§æ‡§Æ ⁄©ÿß ÿ¥€Åÿ± ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∂‡§π‡§∞ ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ú‡§æ‡§Ç‡§ö ‡§≤‡•á‡§Ç‡•§"

    final_prompt_list = [
        PERSONA_PROMPT,
        PERSONA_ACK,
        *history,
        {'role': 'user', 'parts': [f"""
        ‡§Ø‡§π‡§æ‡§Å '{city_name}' ‡§ï‡§æ ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§Æ‡•å‡§∏‡§Æ ‡§°‡•á‡§ü‡§æ ‡§π‡•à:
        - ‡§§‡§æ‡§™‡§Æ‡§æ‡§®: {weather_data['temperature']}¬∞C
        - ‡§µ‡§ø‡§µ‡§∞‡§£: {weather_data['description']}
        - ‡§®‡§Æ‡•Ä (Humidity): {weather_data['humidity']}%
        ‡§á‡§∏ ‡§°‡•á‡§ü‡§æ ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞, ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•ã ‡§è‡§ï ‡§∏‡§∞‡§≤ ‡§î‡§∞ ‡§∏‡•ç‡§µ‡§æ‡§≠‡§æ‡§µ‡§ø‡§ï ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ (1-2 ‡§µ‡§æ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç) ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§
        """]}
    ]
    return generate_gemini_response(final_prompt_list)

def handle_crop_recommendation(user_prompt, history):
    final_prompt_list = [
        PERSONA_PROMPT,
        PERSONA_ACK,
        {'role': 'user', 'parts': ['‡§ú‡§¨ ‡§Ü‡§™ ‡§´‡§∏‡§≤‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡•Ç‡§ö‡•Ä ‡§∏‡•Å‡§ù‡§æ‡§§‡•á ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§π‡§∞ ‡§´‡§∏‡§≤ ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§è‡§ï ‡§®‡§à ‡§≤‡§æ‡§á‡§® ‡§™‡§∞ ‡§¶‡•á‡§Ç‡•§ ‡§∏‡•Ç‡§ö‡•Ä ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§¨‡•Å‡§≤‡•á‡§ü ‡§™‡•â‡§á‡§Ç‡§ü ‡§Ø‡§æ ‡§®‡§Ç‡§¨‡§∞‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§']},
        {'role': 'model', 'parts': ['‡§ú‡•Ä, ‡§Æ‡•à‡§Ç ‡§π‡§∞ ‡§´‡§∏‡§≤ ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§è‡§ï ‡§®‡§à ‡§≤‡§æ‡§á‡§® ‡§™‡§∞ ‡§¶‡•Ç‡§Ç‡§ó‡§æ, ‡§¨‡§ø‡§®‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡§®‡§ø‡§∂‡§æ‡§® ‡§ï‡•á‡•§']},
        *history
    ]
    return generate_gemini_response(final_prompt_list)

def handle_government_scheme(user_prompt, history):
    final_prompt_list = [
        PERSONA_PROMPT,
        PERSONA_ACK,
        *history
    ]
    return generate_gemini_response(final_prompt_list)

def handle_general_conversation(user_prompt, history):
    final_prompt_list = [
        PERSONA_PROMPT,
        PERSONA_ACK,
        *history
    ]
    return generate_gemini_response(final_prompt_list)

# ==============================================================================
#  MAIN DJANGO VIEWS
# ==============================================================================
@login_required 
def assistant_page(request):
    if 'chat_history' in request.session:
        del request.session['chat_history']
    return render(request, 'core.html')

def get_greeting(request):
    fallback_greeting = "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•Ç‡§Å‡•§"
    # [MODIFIED] Updated prompt for a more natural greeting
    greeting_prompt = "‡§Ü‡§™ AgriPath ‡§®‡§æ‡§Æ ‡§ï‡•á ‡§è‡§ï AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à‡§Ç‡•§ ‡§è‡§ï ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§õ‡•ã‡§ü‡§æ, ‡§∏‡•ç‡§µ‡§æ‡§≠‡§æ‡§µ‡§ø‡§ï ‡§î‡§∞ ‡§Æ‡•à‡§§‡•ç‡§∞‡•Ä‡§™‡•Ç‡§∞‡•ç‡§£ ‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§ï‡•á‡§µ‡§≤ ‡§è‡§ï ‡§µ‡§æ‡§ï‡•ç‡§Ø‡•§"
    greeting_text = generate_gemini_response(greeting_prompt)
    if "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç" in greeting_text:
        return JsonResponse({'greeting': fallback_greeting})
    return JsonResponse({'greeting': greeting_text})

@csrf_exempt
def process_voice(request):
    if request.method != 'POST': return JsonResponse({'error': 'Invalid request method'}, status=405)
    if not MODEL: return JsonResponse({'response': '‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•á‡§∞‡§æ AI ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§†‡•Ä‡§ï ‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§'}, status=500)

    try:
        data = json.loads(request.body)
        user_prompt = data.get('text')
        if not user_prompt: return JsonResponse({'error': 'No text provided'}, status=400)

        history = request.session.get('chat_history', [])
        history.append({'role': 'user', 'parts': [user_prompt]})

        classifier_prompt = f"""User query: "{user_prompt}". Classify this into: 'weather', 'crop_recommendation', 'government_scheme', 'general_conversation'. Respond only with the category name."""
        category = generate_gemini_response(classifier_prompt).strip().lower()

        final_response_text = ""
        if 'weather' in category:
            final_response_text = handle_weather_query(user_prompt, history)
        elif 'crop' in category:
            final_response_text = handle_crop_recommendation(user_prompt, history)
        elif 'scheme' in category or 'yojana' in category or 'sarkari' in category:
            final_response_text = handle_government_scheme(user_prompt, history)
        else:
            final_response_text = handle_general_conversation(user_prompt, history)

        history.append({'role': 'model', 'parts': [final_response_text]})
        request.session['chat_history'] = history

        return JsonResponse({'response': final_response_text})

    except json.JSONDecodeError:
        return JsonResponse({'error': 'Invalid JSON in request body'}, status=400)
    except Exception as e:
        print(f"üî¥ An unexpected error occurred in process_voice: {e}")
        return JsonResponse({'error': 'Sorry, an internal server error occurred.'}, status=500)


@csrf_exempt
def clear_chat(request):
    if 'chat_history' in request.session:
        del request.session['chat_history']
    return JsonResponse({'status': 'success', 'message': 'Chat history cleared.'})